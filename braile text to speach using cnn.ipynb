{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import PIL\n",
    "import cv2\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the image dataset\n",
    "\n",
    "os.mkdir('./images/')\n",
    "alpha = 'a'\n",
    "for i in range(0, 26): \n",
    "    os.mkdir('./images/' + alpha)\n",
    "    alpha = chr(ord(alpha) + 1)\n",
    "\n",
    "for file in os.listdir(rootdir):\n",
    "    letter = file[0]\n",
    "    try:\n",
    "        shutil.copy(rootdir+file, './images/' + letter + '/' + file)\n",
    "    except :\n",
    "        print(file)\n",
    "        \n",
    "datagen = ImageDataGenerator(rotation_range=20,\n",
    "                             shear_range=10,\n",
    "                             validation_split=0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_directory('./images/',\n",
    "                                              target_size=(28,28),\n",
    "                                              subset='training')\n",
    "\n",
    "val_generator = datagen.flow_from_directory('./images/',\n",
    "                                            target_size=(28,28),\n",
    "                                            subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model training\n",
    "\n",
    "model_ckpt = ModelCheckpoint('BrailleNet.h5',save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(patience=8,verbose=0)\n",
    "early_stop = EarlyStopping(patience=15,verbose=1)\n",
    "\n",
    "entry = layers.Input(shape=(28,28,3))\n",
    "x = layers.SeparableConv2D(64,(3,3),activation='relu')(entry)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "x = layers.SeparableConv2D(128,(3,3),activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "x = layers.SeparableConv2D(256,(2,2),activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling2D()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Dense(64,kernel_regularizer=l2(2e-4))(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Dense(26,activation='softmax')(x)\n",
    "\n",
    "model = Model(entry,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimiser \n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing and predicting the model\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              validation_data=val_generator,\n",
    "                              epochs=50,\n",
    "                              callbacks=[model_ckpt,reduce_lr,early_stop],\n",
    "                              verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
